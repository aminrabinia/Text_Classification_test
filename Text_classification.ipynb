{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_classification",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminrabinia/Text_Classification_test/blob/main/Text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xzzM1f446sk"
      },
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "\n",
        "import pandas, xgboost, numpy, textblob, string\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers\n",
        "from tensorflow import keras\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "1p2Wf5D2zpjW",
        "outputId": "82d75028-b846-4ad2-c4c4-3538205bc69b"
      },
      "source": [
        "xlsx_path = \"/content/NLP Take-Home Data (2).xlsx\"\n",
        "data = pd.ExcelFile(xlsx_path)\n",
        "df = data.parse('MLAL Challenge')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chf cmplnt</th>\n",
              "      <th>A/P</th>\n",
              "      <th>icd10encounterdiagcode</th>\n",
              "      <th>icd10encounterdiagdescr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Right Hip pain</td>\n",
              "      <td>Normal hip, slight valgus alignment both hips</td>\n",
              "      <td>M25.551</td>\n",
              "      <td>M25.551: Pain in right hip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>F/U RT foot pain and stiffness/ 18 weeks post ...</td>\n",
              "      <td>RIGHT Bunion 2nd HT + Plantar plate tear (MTP)...</td>\n",
              "      <td>M20.5X1</td>\n",
              "      <td>M20.5X1: Other deformities of toe(s) (acquired...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bilateral Hand pain, Bilateral Shoulder pain</td>\n",
              "      <td>Bilateral Carpal Tunnel Syndrome Right Subacro...</td>\n",
              "      <td>M75.41</td>\n",
              "      <td>M75.41: Impingement syndrome of right shoulder</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Finger pain left thumb</td>\n",
              "      <td>Left thumb ulnar collateral ligament injury Pl...</td>\n",
              "      <td>S53.32XA</td>\n",
              "      <td>S53.32XA: Traumatic rupture of left ulnar coll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MRI results LT foot</td>\n",
              "      <td>Lt peroneal tendon tear</td>\n",
              "      <td>S93.602A</td>\n",
              "      <td>S93.602A: Unspecified sprain of left foot, ini...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          chf cmplnt  ...                            icd10encounterdiagdescr\n",
              "0                                     Right Hip pain  ...                         M25.551: Pain in right hip\n",
              "1  F/U RT foot pain and stiffness/ 18 weeks post ...  ...  M20.5X1: Other deformities of toe(s) (acquired...\n",
              "2       Bilateral Hand pain, Bilateral Shoulder pain  ...     M75.41: Impingement syndrome of right shoulder\n",
              "3                             Finger pain left thumb  ...  S53.32XA: Traumatic rupture of left ulnar coll...\n",
              "4                                MRI results LT foot  ...  S93.602A: Unspecified sprain of left foot, ini...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpoldZpk1Weo",
        "outputId": "b7eca13b-a9b0-485a-c0b9-167326426ee7"
      },
      "source": [
        "labels = []\n",
        "for x in df['icd10encounterdiagcode'][:-1]:\n",
        "  labels.append(str(x[:3]))\n",
        "print(labels[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['M25', 'M20', 'M75', 'S53', 'S93', 'S92', 'M16', 'M75', 'S93', 'M06']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EORoo9zLBt96",
        "outputId": "dcf3c2be-21f7-46dc-a4c7-41ed8e51ca3b"
      },
      "source": [
        "cat_labels = set(labels)\n",
        "cat_labels = list(cat_labels)\n",
        "categorized_labels = []\n",
        "for label in labels:\n",
        "  categorized_labels.append(cat_labels.index(label))\n",
        "print(categorized_labels[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[121, 87, 90, 31, 11, 29, 130, 90, 11, 110]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ID56IJtq2TAl",
        "outputId": "d7bf8112-c829-4d73-abc4-03df4c9ee2c7"
      },
      "source": [
        "texts = []\n",
        "for i in range(len(df['A/P'])-1):\n",
        "  desc = df['icd10encounterdiagdescr'][i]\n",
        "  texts.append(df['A/P'][i] + \" \" + desc[3:])\n",
        "print(texts[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Normal hip, slight valgus alignment both hips .551: Pain in right hip', 'RIGHT Bunion 2nd HT + Plantar plate tear (MTP) [>> Rt distal bunion w/ 2nd CPR reconstruction] .5X1: Other deformities of toe(s) (acquired), right foot', 'Bilateral Carpal Tunnel Syndrome Right Subacromial Impingement Plan Right endoscopic carpal tunnel release Continue vimovo Will call with treatment plan regarding shoulder once we receive results of the MRI from Banner RTC 2 wks post op for right endoscopic carpal tunnel release .41: Impingement syndrome of right shoulder', 'Left thumb ulnar collateral ligament injury Plan Continue left thumb spica splint at all times even at night Light duty at work with 2lb lifting restriction RTC in 4 wks for exam .32XA: Traumatic rupture of left ulnar collateral ligament, initial encounter', 'Lt peroneal tendon tear .602A: Unspecified sprain of left foot, initial encounter', '22yoM with right foot nailgun injury and open 1st-3rd metatarsal fxs and retained foreign body s/p removal of foreign body and I&D 6 weeks postop. Wound and fractures healed without signs of infection. Clinically doing well. MMI. Plan -okay to return to work full duty -will discharge from care per work comp -filled out PPR .314B: Nondisplaced fracture of first metatarsal bone, right foot, initial encounter for open fracture', 'Osteoarthritis of the Left Hip. Now with trochanteric bursitis more symptomatic .12: Unilateral primary osteoarthritis, left hip', 'Doing well post-op. Progressing as expected. .121: Complete rotator cuff tear or rupture of right shoulder, not specified as traumatic', 'Lt peroneal tendon tear .402A: Sprain of unspecified ligament of left ankle, initial encounter', '> Left Rheumatoid forefoot reconstruction .871: Other specified rheumatoid arthritis, right ankle and foot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n917AubM6BVC"
      },
      "source": [
        "trainDF = pandas.DataFrame()\n",
        "trainDF['text'] = texts\n",
        "trainDF['label'] = categorized_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yuMAEVC6hBZ",
        "outputId": "0f6db348-ac91-458b-b9c6-6077549115c9"
      },
      "source": [
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])\n",
        "\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)\n",
        "print('Length of trian', len(train_y))\n",
        "print('Length of valid', len(valid_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of trian 3914\n",
            "Length of valid 1305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxI0hCnC7kW1"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHpym74y8N1Z"
      },
      "source": [
        "!unzip wiki-news-300d-1M.vec.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lePz-DYd8Tnl"
      },
      "source": [
        "# load the pre-trained word-embedding vectors \n",
        "embeddings_index = {}\n",
        "for i, line in enumerate(open('wiki-news-300d-1M.vec')):\n",
        "    values = line.split()\n",
        "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')\n",
        "\n",
        "# create a tokenizer \n",
        "token = text.Tokenizer()\n",
        "token.fit_on_texts(trainDF['text'])\n",
        "word_index = token.word_index\n",
        "\n",
        "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
        "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=70)\n",
        "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=70)\n",
        "\n",
        "# create token-embedding mapping\n",
        "embedding_matrix = numpy.zeros((len(word_index) + 1, 300))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-seUi_G9EZf"
      },
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label, epochs= 10)\n",
        "    \n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    \n",
        "    if is_neural_net:\n",
        "        predictions = predictions.argmax(axis=-1)\n",
        "    \n",
        "    return metrics.accuracy_score(predictions, valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poKFR2r_9yla",
        "outputId": "56e7124e-84cd-4494-a912-4965c35dcf06"
      },
      "source": [
        "def create_rnn_lstm():\n",
        "    # Add an Input Layer\n",
        "    input_layer = layers.Input((70, ))\n",
        "\n",
        "    # Add the word embedding Layer\n",
        "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
        "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
        "\n",
        "    # Add the LSTM Layer\n",
        "    lstm_layer = layers.LSTM(100)(embedding_layer)\n",
        "\n",
        "    # Add the output Layers\n",
        "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
        "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
        "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
        "\n",
        "    # Compile the model\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
        "    model.compile(optimizer=keras.optimizers.Adam(), loss='binary_crossentropy')\n",
        "    \n",
        "    return model\n",
        "\n",
        "classifier = create_rnn_lstm()\n",
        "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
        "print (\"RNN-LSTM, Word Embeddings\",  accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "123/123 [==============================] - 11s 73ms/step - loss: -3337.9470\n",
            "Epoch 2/10\n",
            "123/123 [==============================] - 9s 73ms/step - loss: -15161.6396\n",
            "Epoch 3/10\n",
            "123/123 [==============================] - 9s 73ms/step - loss: -36002.0742\n",
            "Epoch 4/10\n",
            "123/123 [==============================] - 9s 72ms/step - loss: -66128.3359\n",
            "Epoch 5/10\n",
            "123/123 [==============================] - 9s 73ms/step - loss: -105194.7266\n",
            "Epoch 6/10\n",
            "123/123 [==============================] - 9s 73ms/step - loss: -153678.0000\n",
            "Epoch 7/10\n",
            "123/123 [==============================] - 9s 73ms/step - loss: -209854.8438\n",
            "Epoch 8/10\n",
            "123/123 [==============================] - 9s 74ms/step - loss: -274785.9062\n",
            "Epoch 9/10\n",
            "123/123 [==============================] - 9s 72ms/step - loss: -346934.6875\n",
            "Epoch 10/10\n",
            "123/123 [==============================] - 9s 72ms/step - loss: -428259.9688\n",
            "RNN-LSTM, Word Embeddings 0.007662835249042145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESdM8rqB-bS4",
        "outputId": "81c2e2c8-5bb3-48ee-9e26-f99d22a6fc7a"
      },
      "source": [
        "mytext = \"Plan --okay for activity as tolerated --continue gout management --fu PRN\"\n",
        "seq_x = sequence.pad_sequences(token.texts_to_sequences([mytext]), maxlen=70)\n",
        "output = classifier.predict(seq_x)\n",
        "mylabel = cat_labels[int(output[0])]\n",
        "print(\"Predicted ICD10:\", mylabel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted ICD10: M11\n"
          ]
        }
      ]
    }
  ]
}